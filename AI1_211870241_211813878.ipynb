{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to assignment 1! üëèüëè\n",
        "\n",
        "The exercise's objectives are the following:\n",
        "\n",
        "1.   Understand the algorithms you learned in class.\n",
        "2.   Learn how to write code in Python and how to use Google Colab.\n",
        "3.   Have fun!\n"
      ],
      "metadata": {
        "id": "AHjIAUOGMLiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab\n",
        "Colaboratory, or ‚ÄúColab‚Äù for short, is a product from Google Research. Colab allows anybody to write and execute arbitrary python code through the browser, and is especially well suited to AI, machine learning, data analysis and education. More technically, Colab is a hosted Jupyter notebook service that requires no setup to use, while providing free access to computing resources including GPUs.\n",
        "\n",
        "\n",
        "It is recommended to go through this [guide](https://www.datacamp.com/tutorial/tutorial-google-colab-for-data-scientists)\n",
        " before starting.\n"
      ],
      "metadata": {
        "id": "10dRH2qBks16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important tip:** If the same variable name appears in two different cells, the variable value will be determined by the last cell to run, rather than by the position of the cell. Let's see an example,  run the three cells below:"
      ],
      "metadata": {
        "id": "EUhq1ubdDE2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cell 1\n",
        "x = 3"
      ],
      "metadata": {
        "id": "W36S7jvkENyg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cell 2\n",
        "x = 5"
      ],
      "metadata": {
        "id": "kei_W6-QEQD_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "id": "JPQkx5XQETF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ec82eb-6054-4bce-a30f-83e5f431028c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now rerun cell 1 and print x again.\n",
        "\n",
        "The same applies to functions, classes, etc.\n"
      ],
      "metadata": {
        "id": "tO3WdjItEVQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To work with colab, save the assignment in a folder in Google Drive. Match the following two lines in the cell below with the location in which folder has been saved and run the cell.\n",
        "\n",
        "\n",
        "1.   !cp -r /content/drive/MyDrive/ \"**path to the folder**\" /* .\n",
        "2.   sys.path.append('/content/drive/MyDrive/ \"**path to folder**\" /FrozenKaleEnv.py')\n",
        "\n",
        "After running the cell below with the right path, you should see the contents of the assignment folder in the left-hand bar, under \"Files\".\n"
      ],
      "metadata": {
        "id": "fqyEJdJlivGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "### Lior\n",
        "#!cp -r /content/drive/MyDrive/AI-assignment1/* . #line 1\n",
        "#sys.path.append('/content/drive/MyDrive/AI-assignment1/FrozenKaleEnv.py') # line 2\n",
        "\n",
        "### Yotam\n",
        "!cp -r /content/drive/MyDrive/Technion/'2022 23'/'Winter 2022'/'Intro. to AI'/Homework/'HW#1'/* . #line 1\n",
        "sys.path.append('/content/FrozenLakeEnv.py') # line 2"
      ],
      "metadata": {
        "id": "JbeKpb1q3yiu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c15d130-27ac-43f7-fae4-4fe2f01d3fd6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting started with Open AI gym\n",
        "\n",
        "[OpenAI Gym](http://gym.openai.com) is a toolkit for comparing AI and RL algorithms. It contains a wide variety of environments that you can train your agents on, and it is often used for benchmarking new methods in the AI research literature. \n",
        "There are also [leaderboards](https://github.com/openai/gym/wiki/Leaderboard) for different gym-environments, showing which methods have been most successful so far.\n",
        "\n",
        "In this assignments we will use OpenAI gym (within the course's scope).\n",
        "\n"
      ],
      "metadata": {
        "id": "daeBGgC4Oou-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Environment\n",
        "You will work on a custom version of the [Frozen Lake](https://www.gymlibrary.dev/environments/toy_text/frozen_lake/) environment from OpenAI.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "1. Your goal is to find a route from the top left corner to the bottom right corner.\n",
        "2. Each position on the map is marked with a letter, and each letter has a different meaning:\n",
        "\n",
        "  *   S - Initial (start) position. There's only one initial state on the map and it's always at the upper left corner.\n",
        "  *   G - Final state. There's only one final state on the map and it's always in the lower right corner.\n",
        "  *   H - Hole. When your agent reachs a hole, it falls into the water and cannot continue walking.\n",
        "  *   P -  Portal. There are either two or zero portals on the map. When the agent reaches a portal, it is immediately transported to the other portal. You can assume that they will not appear in a final or initial state.\n",
        "  *   F -  Frozen lake. This is the most common square on the map. The agent can walk on it safely.\n",
        "\n",
        "  Your agent can move faster by collecting 3 special objects.\n",
        "\n",
        "  *   T - [Talaria](https://en.wikipedia.org/wiki/Talaria). A pair of Winged Sandals that help you fly to the square.\n",
        "  *   A - Air jorden. Jumping shoes that help you jump to the square.\n",
        "  *   L - Lightning. Makes you run faster to the square.\n",
        "\n",
        "  When the agent performs transition (s,a,s') and collects one of the objects (T,A,L) at state s', the collected object changes the cost of the transition (as detailed below). \n",
        "\n",
        "3. The cost of each transition (s,a,s') is based on the mark if the square s' you pass to:\n",
        "  * S - 1\n",
        "  * G - 1\n",
        "  * H - 0\n",
        "  * P - 100\n",
        "  * F - 10\n",
        "  * T - 3\n",
        "  * A - 2\n",
        "  * L - 1\n",
        "\n",
        "4. The pink square marks where your agent is.\n",
        "\n",
        "5. The number of states is equal to the number of squares on the map. The state index is calculated as follows: row_number *num_col + col_ number*. For example, the state index of the portal squere on row 3 is : 3 * 8 + 1 = 25.\n",
        "\n",
        "6. Our agent can perform 4 actions:\n",
        "  * 0 - Down\n",
        "  * 1 - Right\n",
        "  * 2 - Up\n",
        "  * 3 - Left\n",
        "  \n",
        "\n",
        "7. If the agent tries to move outside the board boundaries, he stays in the same place.\n",
        "\n",
        "8. Section 6 describes the order in which the nodes should be created.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ik_YMt0HO_R9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import gym\n",
        "from gym import Env, logger, spaces, utils\n",
        "from gym.envs.toy_text.utils import categorical_sample\n",
        "from gym.error import DependencyNotInstalled\n",
        "\n",
        "from FrozenLakeEnv import FrozenLakeEnv\n",
        "from typing import List, Tuple\n",
        "import heapdict\n",
        "\n"
      ],
      "metadata": {
        "id": "XIvTBylGni-J"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DOWN = 0\n",
        "RIGHT = 1\n",
        "UP = 2\n",
        "LEFT = 3"
      ],
      "metadata": {
        "id": "iHTZ1L7bcMlw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Maps\n",
        "A map can be produced manually as shown in the cell below. We will only work on maps in which there is a route from the initial state to the final state."
      ],
      "metadata": {
        "id": "EWEiS5mVn7mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAPS = {\n",
        "    \"5x5\": [\"SHLLL\",\n",
        "            \"FHLHL\",\n",
        "            \"FLLHL\",\n",
        "            \"FHHHL\",\n",
        "            \"FFFFG\"],\n",
        "    \"4x4\": [\"SFFF\",\n",
        "            \"FHFH\",\n",
        "            \"FFFH\",\n",
        "            \"HFFG\"],\n",
        "    \"8x8\": [\n",
        "        \"SFFFFFFF\",\n",
        "        \"FFFFFTAL\",\n",
        "        \"TFFHFFTF\",\n",
        "        \"FPFFFHTF\",\n",
        "        \"FAFHFPFF\",\n",
        "        \"FHHFFFHF\",\n",
        "        \"FHTFHFTL\",\n",
        "        \"FLFHFFFG\"]\n",
        "}"
      ],
      "metadata": {
        "id": "MaIE0Yqenp2O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# The Frozen Lake Environment ‚õ∑\n",
        "The file `FrozenLakeEnv.py` implements our own version of the frozen lake environment. It is recommended to go through the code. \n",
        "\n",
        "**Note: You are not allowed to change this file.**"
      ],
      "metadata": {
        "id": "qIpo4KAgxE9q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets start by creating a new environment object.\n",
        "\n",
        "In order to create an environment object, you must provide it with a board."
      ],
      "metadata": {
        "id": "jRBezhLKIIJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = FrozenLakeEnv(MAPS[\"8x8\"])\n",
        "state = env.reset()\n",
        "print('Initial state:', state)    "
      ],
      "metadata": {
        "id": "9ce62lyU8L39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77aa869f-ae43-4ff1-e59e-665f500910c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial state: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, take a look at the state space $\\mathcal{S}$ (all possible states) and action space $\\mathcal{A}$ (all possible actions). "
      ],
      "metadata": {
        "id": "BWYU-zl1J1_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Action Space {env.action_space}\")\n",
        "print(f\"State Space {env.observation_space}\")"
      ],
      "metadata": {
        "id": "Cg7XAAByJ-IH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "752fd12a-162c-4692-9684-b65ff6bc9f4e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space Discrete(4)\n",
            "State Space Discrete(64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Remark***: You may have noticed that gym uses `observation_space` instead of state space. For the purpose of this homework, the state space is the same as the observations space. However, in some problems the full state cannot be observed, so the space of possible states may not be the same as the space of possible observations. \n",
        "\n"
      ],
      "metadata": {
        "id": "wqptD9FjiYni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will go throught some usfel methods (It is still recommended to go through the other methods in the class):\n",
        "\n",
        "`render()` - returns a printable view of the board."
      ],
      "metadata": {
        "id": "BASrtg6SHjFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(env.render())"
      ],
      "metadata": {
        "id": "kDNpfddaBWJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad0f806-06ed-4cc2-e7c3-e96a674f8ab6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[43m\u001b[45mS\u001b[0m\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mA\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[43mG\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pink square represents the agent. The letter ◊¥*H*◊¥ represents holes, and the yellow square is the final state.\n",
        "\n",
        "Here are two more useful methods:\n",
        "\n",
        "`get_state()` - Returns the current state of the agent.\n",
        "\n",
        "`set_state(state)` - Sets the current state of the agent."
      ],
      "metadata": {
        "id": "ZAaEmhts9vAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.set_state(18)\n",
        "print(env.render())\n",
        "print(f\"the agent is at state: {env.get_state()}\")"
      ],
      "metadata": {
        "id": "43Z9On8M--ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5063febc-9a16-492a-f40c-5dff5bfc0d22"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[43mS\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mA\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[45m\u001b[45mF\u001b[0m\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[43mG\u001b[0m\n",
            "\n",
            "the agent is at state: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`succ(state)` - Returns a dictionary that contains information on all the successors of a state.\n",
        "\n",
        "*   The keys are the actions.\n",
        "*   The values are tuples of the form (next state, cost, terminated). Note that terminated is true when the agent reaches a **final state** or a **hole**.\n",
        "\n",
        "\n",
        "\n",
        "***Tip***: You can loop through both keys and values by using the `items()` method.\n"
      ],
      "metadata": {
        "id": "6VwmIbSyAcsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "current_state = env.get_state()\n",
        "print(f\"Current state: {current_state}\\n\")\n",
        "for action, successor in env.succ(current_state).items():\n",
        "  print(f\"*** Action: {action} ***\")\n",
        "  print(f\"Next state: {successor[0]}\")\n",
        "  print(f\"Cost: {successor[1]}\")\n",
        "  print(f\"Terminated: {successor[2]}\\n\")"
      ],
      "metadata": {
        "id": "vZ7l6kSnAxvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24cfc6d7-2b43-4f3d-ac2b-23b1f93840df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current state: 18\n",
            "\n",
            "*** Action: 0 ***\n",
            "Next state: 26\n",
            "Cost: 10.0\n",
            "Terminated: False\n",
            "\n",
            "*** Action: 1 ***\n",
            "Next state: 19\n",
            "Cost: 0.0\n",
            "Terminated: True\n",
            "\n",
            "*** Action: 2 ***\n",
            "Next state: 10\n",
            "Cost: 10.0\n",
            "Terminated: False\n",
            "\n",
            "*** Action: 3 ***\n",
            "Next state: 17\n",
            "Cost: 10.0\n",
            "Terminated: False\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the action 0 (down) will move your agent to state 26 and the transition will cost you 10. Action 1 will move your agent to state 19, which is a hole that will terminate your run.\n",
        "\n",
        "`is_final_state(state)` can assist you in distinguishing between a final state and a hole."
      ],
      "metadata": {
        "id": "f2qFBBDWBcVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state, cost, terminated = env.succ(current_state)[1]\n",
        "\n",
        "print(f\"Next state: {state}\")\n",
        "print(f\"Cost: {cost}\")\n",
        "print(f\"Terminated: {terminated}\")\n",
        "print(f\"Final state: {env.is_final_state(state)}\")"
      ],
      "metadata": {
        "id": "7j097OzTBZ_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb7b602-a656-4cc0-91bb-bb519898a0a4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next state: 19\n",
            "Cost: 0.0\n",
            "Terminated: True\n",
            "Final state: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what happens when we apply succ(state) on a hole:\n",
        "\n"
      ],
      "metadata": {
        "id": "ptr9kbNole-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Current state: 19\\n\")\n",
        "for action, successor in env.succ(19).items():\n",
        "  print(f\"*** Action: {action} ***\")\n",
        "  print(f\"Next state: {successor[0]}\")\n",
        "  print(f\"Cost: {successor[1]}\")\n",
        "  print(f\"Terminated: {successor[2]}\\n\")"
      ],
      "metadata": {
        "id": "GcpKGM5yli4M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41994364-ebf7-4b0e-c531-bb0344581354"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current state: 19\n",
            "\n",
            "*** Action: 0 ***\n",
            "Next state: None\n",
            "Cost: None\n",
            "Terminated: None\n",
            "\n",
            "*** Action: 1 ***\n",
            "Next state: None\n",
            "Cost: None\n",
            "Terminated: None\n",
            "\n",
            "*** Action: 2 ***\n",
            "Next state: None\n",
            "Cost: None\n",
            "Terminated: None\n",
            "\n",
            "*** Action: 3 ***\n",
            "Next state: None\n",
            "Cost: None\n",
            "Terminated: None\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, if the operator cannot be applied to the state, all returned values are \"None\""
      ],
      "metadata": {
        "id": "dxny4BVOr-UT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's time to move your agent around ü§ñ.\n",
        "\n",
        "`step(action)` - will move your agent one step along the board.\n"
      ],
      "metadata": {
        "id": "FXDKjWAoCqW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_state, cost, terminated = env.step(DOWN)\n",
        "print(env.render())\n",
        "print(\"New state:\", new_state)\n",
        "print(\"cost:\", cost)\n",
        "print(\"Terminated:\", terminated)"
      ],
      "metadata": {
        "id": "gLWj_oYaFM33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8fa18d0-6ffa-462c-a512-3f88f7dfe581"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Down)\n",
            "\u001b[43mS\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mA\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[45m\u001b[45mF\u001b[0m\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[43mG\u001b[0m\n",
            "\n",
            "New state: 26\n",
            "cost: 10.0\n",
            "Terminated: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The step-function returns the following information:\n",
        "* __New state__: The state after the action is taken.\n",
        "* __Cost__: The immediate cost.\n",
        "* __Terminated__: Is the environment done? In our environment this will be false until the agent will reach a hole or a final state.\n",
        "\n",
        "Let's move your agent one step left towards the portal and see what happens."
      ],
      "metadata": {
        "id": "HHcHkCw8FipY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_state, cost, done = env.step(LEFT)\n",
        "print(env.render())\n",
        "print(\"New state:\", new_state)\n",
        "print(\"cost:\", cost)\n",
        "print(\"Done:\", done)"
      ],
      "metadata": {
        "id": "dcEj7pZQFhdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9471b885-21f9-45d1-ce65-fc5f3f1161f8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Left)\n",
            "\u001b[43mS\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mA\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[45m\u001b[45mP\u001b[0m\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[43mG\u001b[0m\n",
            "\n",
            "New state: 37\n",
            "cost: 100\n",
            "Done: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Have you noticed that your agent has moved to the second portalüò≤?\n",
        "\n",
        "On some maps, the portals can significantly shorten your route, but going through them is much more expensive, so it is not always advisable.\n"
      ],
      "metadata": {
        "id": "6XRITGRPGsfU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are a few more useful attributes and methods:\n",
        "\n",
        "\n",
        "`env.nrow`, `env.ncol` - Row and columns number.\n",
        "\n",
        "`env.nA` - Number of actions.\n",
        "\n",
        "`env.nS` - Number of states.\n",
        "\n",
        "`env.lastaction` - The last action performed by the agent.\n",
        "\n",
        "`env.p1`, `env.p2` - This is the state number for each portal. If there are no portals on the board they are set to NULL.\n",
        "\n",
        "`env.inc(row, col, action)` - Given a position and an action, returns the new position.\n",
        "\n",
        "`env.to_row_col(state)` - Converts between state and location on the board.\n",
        "\n",
        "`env.to_state(row, col)` - Converts between location on the board and state.\n",
        "\n"
      ],
      "metadata": {
        "id": "qh9NM7qDlxUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've finished our demo ü•≥ and it's time to reset the environment."
      ],
      "metadata": {
        "id": "xoxs3sG0QyhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"current state befor reset: {env.get_state()}\")\n",
        "env.reset()\n",
        "print(f\"current state after reset: {env.get_state()}\")\n"
      ],
      "metadata": {
        "id": "MfjMsGRnHoK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3dea4a-27fa-47d2-ee08-4668c77d7c55"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current state befor reset: 37\n",
            "current state after reset: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One (quite bad) strategy for out agent is to take a random action every time. Inside a gym-environment this can be done using `env.action_space.sample()`, which samples a random action from the action space. Look through the following loop and make sure that you understand what's going on. Here, we use `clear_output()` to clear the output of the Jupyter cell, and `time.sleep()` to pause between each action)\n",
        "\n",
        "\n",
        "Let's see what would happen if we try to brute-force our way to solving the problem.\n",
        "\n",
        "\n",
        "We'll create an infinite loop that runs until the agent reaches the final state.The `env.action_space.sample()` method automatically selects one random action from set of all possible actions."
      ],
      "metadata": {
        "id": "KYqbtBE_kzDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomAgent():\n",
        "  def __init__(self):\n",
        "    self.env = None\n",
        "\n",
        "  def animation(self, epochs: int ,state: int, action: List[int], total_cost: int) -> None:\n",
        "      clear_output(wait=True)\n",
        "      print(self.env.render())\n",
        "      print(f\"Timestep: {epochs}\")\n",
        "      print(f\"State: {state}\")\n",
        "      print(f\"Action: {action}\")\n",
        "      print(f\"Total Cost: {total_cost}\")\n",
        "      time.sleep(1)\n",
        "\n",
        "  def random_search(self, FrozenLakeEnv: env) -> Tuple[List[int],int]:\n",
        "    self.env = env\n",
        "    self.env.reset()\n",
        "    epochs = 0\n",
        "    cost = 0\n",
        "    total_cost = 0\n",
        "\n",
        "    actions = []\n",
        "\n",
        "    state = self.env.get_initial_state()\n",
        "    while not self.env.is_final_state(state):\n",
        "      action = self.env.action_space.sample()\n",
        "      new_state, cost, terminated = self.env.step(action)\n",
        "        \n",
        "      while terminated is True and self.env.is_final_state(state) is False:\n",
        "        self.env.set_state(state)\n",
        "        action = self.env.action_space.sample()\n",
        "        new_state, cost, terminated = self.env.step(action)\n",
        "        \n",
        "      actions.append(action)\n",
        "      total_cost += cost\n",
        "      state = new_state\n",
        "      epochs += 1\n",
        "      \n",
        "      self.animation(epochs,state,action,total_cost)\n",
        "\n",
        "    return (actions, total_cost)\n"
      ],
      "metadata": {
        "id": "MZE__OgBx78N"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check out this agent's performance!\n",
        "\n",
        "The output of this agent is the sequence of actions that led to the solution and the route's cost. \n",
        "\n",
        "Our random agent is not very successful, so we'll print his actions as they happen. \n",
        "\n",
        "1.   **Stop his run in the middle if you are tired of looking at him.**\n",
        "2.   After watching the agent please put the code in the box below in the a comment. During testing, we do not want the notebook to get stuck in this box.\n",
        "\n",
        " \n",
        "\n"
      ],
      "metadata": {
        "id": "QJ9FDJWNZr3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#agent = RandomAgent()\n",
        "#agent.random_search(env)"
      ],
      "metadata": {
        "id": "8Gc3-gJVZH3h"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Did you remember to put the code above in a comment?!**"
      ],
      "metadata": {
        "id": "FW7YKLjCi4Qf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, a random policy is, unsurprisingly, not a good policy. However, what else can we do?\n",
        "\n",
        "This is where you come in!\n",
        "\n",
        "In this assignment you will be required to implement the following algorithms taught in class in order to solve the problem.\n",
        "\n",
        "Algorithms: \n",
        "1. BFS-G\n",
        "2. DFS-G\n",
        "3. ID-DFS-G\n",
        "4. Uniform Cost Search (UCS)\n",
        "5. Greedy Best Search\n",
        "6. W-A*\n",
        "7. A* epsilon\n",
        "\n",
        "Important to note!\n",
        "\n",
        "Each agent should return a tuple: (actions, cost, expended) \n",
        "*  actions - the list of integers containing the sequence of actions that produce your agent's solution (and not the entire search process).\n",
        "* cost -  an integer which holds the total cost of the solution.\n",
        "* expanded - an integer which holds the number of nodes that have been expanded during the search.\n",
        "\n",
        "The solution to our search problem is the path to the final state, not the final state itself (since it is known). By saving the actions, we are able to restore the path your agent found.\n",
        "\n",
        "\n",
        "Any other output, unless otherwise specified, will cause the running of the notebook to fail and will result in a grade of 0 !\n",
        "\n"
      ],
      "metadata": {
        "id": "qBKDB1Aja5JB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Some Tips:\n",
        "1. Follow the pseudo-code shown in the lectures.\n",
        "2. You should write all your code within the classes. This way, we prevent overlapping functions with the same name while running the notebook.\n",
        "3. Consider implementing a \"node\" class.\n",
        "4. Using small boards will help you debug.\n"
      ],
      "metadata": {
        "id": "-nikK0HKwhRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function below (`print_solution()`) can be used for debugging purposes. It prints the sequence of actions it receives. The function will not be used to test your code, so you are welcome to change it."
      ],
      "metadata": {
        "id": "lMwTzaJKw9gA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_solution(actions,env: FrozenLakeEnv) -> None:\n",
        "    env.reset()\n",
        "    total_cost = 0\n",
        "    print(env.render())\n",
        "    print(f\"Timestep: {1}\")\n",
        "    print(f\"State: {env.get_state()}\")\n",
        "    print(f\"Action: {None}\")\n",
        "    print(f\"Cost: {0}\")\n",
        "    time.sleep(1)\n",
        "\n",
        "    for i, action in enumerate(actions):\n",
        "      state, cost, terminated = env.step(action)\n",
        "      total_cost += cost\n",
        "      clear_output(wait=True)\n",
        "\n",
        "      print(env.render())\n",
        "      print(f\"Timestep: {i + 2}\")\n",
        "      print(f\"State: {state}\")\n",
        "      print(f\"Action: {action}\")\n",
        "      print(f\"Cost: {cost}\")\n",
        "      print(f\"Total cost: {total_cost}\")\n",
        "      \n",
        "      time.sleep(1)\n",
        "\n",
        "      if terminated is True:\n",
        "        break"
      ],
      "metadata": {
        "id": "WQj77NFT0Wdc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Node Implementation:**"
      ],
      "metadata": {
        "id": "QoT9Ze-GwcID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  def __init__(self, env, state, action, parent, total_cost):\n",
        "    self.state = state\n",
        "    self.action = action\n",
        "    self.env = env\n",
        "    self.parent = parent\n",
        "    self.total_cost = total_cost\n",
        "\n",
        "  def __eq__(self,s):\n",
        "    return self.state == s\n",
        "\n",
        "  def __hash__(self):\n",
        "    return hash(self.state)\n",
        "\n",
        "  def expand(self):\n",
        "    sons = []\n",
        "    for action, successor in self.env.succ(self.state).items():\n",
        "      if (successor[0] != None):\n",
        "        sons.append(Node(self.env, successor[0], action, self, self.total_cost+successor[1]))\n",
        "    return sons\n",
        "\n",
        "  def path(self):\n",
        "    parent_path = []\n",
        "    node = self\n",
        "    while node.parent != None:\n",
        "      parent_path = [node.action] + parent_path\n",
        "      node = node.parent\n",
        "    return parent_path\n",
        "\n",
        "class Heuristic_Node(Node):\n",
        "  def __init__(self, env, state, action, parent, total_cost):\n",
        "    super().__init__(env, state, action, parent, total_cost)\n",
        "    self.h = self.h_sap(state)\n",
        "    self.f = self.calc_f()\n",
        "\n",
        "  def h_sap(self, state):\n",
        "    row, col = self.env.to_row_col(state)\n",
        "    return min(100, self.env.nrow - 1 - row + self.env.ncol - 1 - col)\n",
        "\n",
        "  def calc_f(self):\n",
        "    return self.h + self.total_cost\n",
        "\n",
        "  def expand(self):\n",
        "    sons = []\n",
        "    for action, successor in self.env.succ(self.state).items():\n",
        "      if (successor[0] != None):\n",
        "        sons.append(Heuristic_Node(self.env, successor[0], action, self, self.total_cost+successor[1]))\n",
        "    return sons"
      ],
      "metadata": {
        "id": "dzjLRPNNwUgS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. BFS-G\n",
        "**TO DO:** implement Breadth First Search (BFS) algorithm on graph like shown in class.\n"
      ],
      "metadata": {
        "id": "8zGQKO6ka-5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BFSAgent:\n",
        "    def __init__(self):\n",
        "      self.env = None\n",
        "\n",
        "    def bfs_search(self, env: FrozenLakeEnv)-> Tuple[List[int], int, int]:\n",
        "      self.env = env\n",
        "      self.env.reset()\n",
        "      initial = Node(env, env.get_initial_state(), None, None, 0)\n",
        "\n",
        "      # It's given that the initial state isn't a goal state -> no need to check it like in the psuedo-code\n",
        "      open = [initial]\n",
        "      close = []; expanded = 0\n",
        "      while len(open) != 0:\n",
        "        n = open.pop(0) # FIFO queue\n",
        "        env.set_state(n.state)\n",
        "        close.append(n.state)\n",
        "        ex = n.expand()\n",
        "        expanded += 1\n",
        "        for son in ex:\n",
        "          if (not son.state in close) and (not son in open):\n",
        "            if env.is_final_state(son.state):\n",
        "              return son.path(), son.total_cost, expanded\n",
        "            open.append(son)"
      ],
      "metadata": {
        "id": "Dstm3kWhbCaE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets test your BFS agent!"
      ],
      "metadata": {
        "id": "XfoBu-elP2To"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BFS_agent = BFSAgent()\n",
        "actions, total_cost, expanded = BFS_agent.bfs_search(env)\n",
        "print(f\"Total_cost: {total_cost}\")\n",
        "print(f\"Expanded: {expanded}\")\n",
        "print(f\"Actions: {actions}\")"
      ],
      "metadata": {
        "id": "VyTnlxozM-U6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab1ce82-6adf-4fdb-fe3c-044bb6b3b782"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total_cost: 164.0\n",
            "Expanded: 55\n",
            "Actions: [0, 0, 0, 1, 0, 0, 0, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_solution(actions, env)"
      ],
      "metadata": {
        "id": "B6cGuGv6nAqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4301d5a-1c92-4b8d-8021-2b42d32ae50e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Right)\n",
            "\u001b[43mS\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mA\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[45m\u001b[45mG\u001b[0m\u001b[0m\n",
            "\n",
            "Timestep: 10\n",
            "State: 63\n",
            "Action: 1\n",
            "Cost: 1.0\n",
            "Total cost: 164.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. DFS-G\n",
        "**TO DO:** implement Depth First Search (DFS) algorithm on graph like shown in class.\n"
      ],
      "metadata": {
        "id": "XPab1LWaqmc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DFSAgent:\n",
        "  def __init__(self):\n",
        "    self.env = None\n",
        "  \n",
        "  def dfs_search(self, env: FrozenLakeEnv)->Tuple[List[int], int, int]:\n",
        "    self.result = False\n",
        "    self.env = env\n",
        "    self.env.reset()\n",
        "    initial = Node(env, env.get_initial_state(), None, None, 0)\n",
        "\n",
        "    # It's given that the initial state isn't a goal state -> no need to check it like in the psuedo-code\n",
        "    open = [initial]\n",
        "    close = []; self.expanded = 0\n",
        "    path, total_cost = self.recursive_dfs(open, close)\n",
        "    return path, total_cost, self.expanded\n",
        "\n",
        "  def recursive_dfs(self, open, close):\n",
        "    env = self.env\n",
        "    n = open.pop(len(open)-1) # LIFO queue\n",
        "    env.set_state(n.state)\n",
        "    close.append(n.state)\n",
        "    \n",
        "    # base case\n",
        "    if env.is_final_state(n.state):\n",
        "      self.result = True\n",
        "      return n.path(), n.total_cost\n",
        "    \n",
        "    ex = n.expand()\n",
        "    self.expanded += 1\n",
        "    # recursive steps\n",
        "    for son in ex:\n",
        "      if (not son.state in close) and (not son in open) and self.result==False:\n",
        "        open.append(son)\n",
        "        path, total_cost = self.recursive_dfs(open, close)  \n",
        "      if self.result != False:\n",
        "        return path, total_cost\n",
        "        \n",
        "    return None, None"
      ],
      "metadata": {
        "id": "38Y47FjwUsEO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets test your DFS agent!"
      ],
      "metadata": {
        "id": "kjAPRyCcQt82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DFS_agent = DFSAgent()\n",
        "actions, total_cost, expanded = DFS_agent.dfs_search(env)\n",
        "print(f\"Total_cost: {total_cost}\")\n",
        "print(f\"Expanded: {expanded}\")\n",
        "print(f\"Actions: {actions}\")"
      ],
      "metadata": {
        "id": "sxvfljY8rYYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b910d13-78d6-43f0-8b17-513c6e8981a5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total_cost: 148.0\n",
            "Expanded: 20\n",
            "Actions: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_solution(actions, env)"
      ],
      "metadata": {
        "id": "3t05mYuOkT_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ad47034-a030-4d0d-d96b-145054e49a5a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Right)\n",
            "\u001b[43mS\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mA\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[45m\u001b[45mG\u001b[0m\u001b[0m\n",
            "\n",
            "Timestep: 19\n",
            "State: 63\n",
            "Action: 1\n",
            "Cost: 1.0\n",
            "Total cost: 148.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ID-DFS-G\n",
        "**TO DO:** implement Iterative Deepening Depth First Search (ID-DFS) like shown in class. \n",
        "\n",
        "\n",
        "To find a solution, your agent needs to run the DFS-L-G (on graph) algorithm and go one step deeper with each iteration. You can assume that your code will not be interrupted in the middle of its execution. Thus, your agent should continue searching for a solution until a solution is found.\n"
      ],
      "metadata": {
        "id": "p6o30STBteuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IDDFSAgent:\n",
        "    def __init__(self):\n",
        "        self.env = None\n",
        "        \n",
        "    class DFSLAgent:\n",
        "      def __init__(self):\n",
        "        self.env = None\n",
        "  \n",
        "      def dfsl_search(self, env: FrozenLakeEnv, l)->Tuple[List[int], int, int]:\n",
        "        self.result = False\n",
        "        self.env = env\n",
        "        self.env.reset()\n",
        "        initial = Node(env, env.get_initial_state(), None, None, 0)\n",
        "\n",
        "        # It's given that the initial state isn't a goal state -> no need to check it like in the psuedo-code\n",
        "        open = [initial]\n",
        "        close = []; self.expanded = 0\n",
        "        path, total_cost = self.recursive_dfsl(open, close, l)\n",
        "        return path, total_cost, self.expanded\n",
        "\n",
        "      def recursive_dfsl(self, open, close, l):\n",
        "        env = self.env\n",
        "        n = open.pop(len(open)-1) # LIFO queue\n",
        "        env.set_state(n.state)\n",
        "        close.append(n.state)\n",
        "        \n",
        "        # base case\n",
        "        if env.is_final_state(n.state):\n",
        "          self.result = True\n",
        "          return n.path(), n.total_cost\n",
        "        \n",
        "        ##if length is 0->failure\n",
        "        if (l==0):\n",
        "            return None, None\n",
        "\n",
        "        ex = n.expand()\n",
        "        self.expanded += 1\n",
        "        # recursive steps\n",
        "        for son in ex:\n",
        "          if (not son.state in close) and (not son in open) and self.result==False:\n",
        "            open.append(son)\n",
        "            path, total_cost = self.recursive_dfsl(open, close, l-1)  \n",
        "          if self.result != False:\n",
        "            return path, total_cost\n",
        "            \n",
        "        return None, None\n",
        "    \n",
        "    def id_dfs_search(self, env: FrozenLakeEnv,) -> Tuple[List[int], int ,int]:\n",
        "      l=0\n",
        "      DFS_L_agent = self.DFSLAgent()\n",
        "      expanded=0\n",
        "      while True:\n",
        "        actions, total_cost, expanded_iteration= DFS_L_agent.dfsl_search(env,l)\n",
        "        expanded= expanded + expanded_iteration\n",
        "        if actions != None:\n",
        "          return actions, total_cost, expanded\n",
        "        l=l+1"
      ],
      "metadata": {
        "id": "xasfBvXptf42"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ID_DFS_agent = IDDFSAgent()\n",
        "actions, total_cost, expanded = ID_DFS_agent.id_dfs_search(env)\n",
        "print(f\"Total_cost: {total_cost}\")\n",
        "print(f\"Expanded: {expanded}\")\n",
        "print(f\"Actions: {actions}\")"
      ],
      "metadata": {
        "id": "CTiDCJs7tzS-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a2eb956-4efb-4d7b-ce91-4727b2ea5661"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total_cost: 155.0\n",
            "Expanded: 360\n",
            "Actions: [0, 0, 0, 1, 1, 1, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_solution(actions, env)"
      ],
      "metadata": {
        "id": "y7wNtzJhTu9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d785516c-36c0-4624-c04c-718d53e88c94"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Down)\n",
            "\u001b[43mS\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mA\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[45m\u001b[45mG\u001b[0m\u001b[0m\n",
            "\n",
            "Timestep: 10\n",
            "State: 63\n",
            "Action: 0\n",
            "Cost: 1.0\n",
            "Total cost: 155.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Heapdict\n",
        "For the next algorithms, you will be required to maintain an \"open\" queue based on a certain value (g/h/v). To manage these queues efficiently and conveniently, please use [Heapdict](https://www.geeksforgeeks.org/priority-queue-using-queue-and-heapdict-module-in-python/). Heapdict implements the MutableMapping ABC, meaning it works pretty much like a regular Python [dictionary](https://www.geeksforgeeks.org/python-dictionary/). It‚Äôs designed to be used as a priority queue. Along with functions provided by ordinary dict(), it also has popitem() and peekitem() functions which return the pair with the lowest priority.\n",
        "\n",
        "Note:\n",
        "\n",
        "1.   When two nodes have the same minimum value, select the node with the lower state index first. Instead of defining priority as an integer, you can define it as a tuple (value, state).\n",
        "2.   To update a node in ◊¥open◊¥, please remove it from heapdict and re-insert it.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZIkPei1WKdKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Uniform Cost Search (UCS)\n",
        "TO DO: implement Uniform Cost Search (UCS) like shown in class.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l78oM31_xo60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UCSAgent:\n",
        "    def __init__(self):\n",
        "      self.env = None\n",
        "\n",
        "    def ucs_search(self, env: FrozenLakeEnv) -> Tuple[List[int], int ,int]:\n",
        "      self.env = env\n",
        "      self.env.reset()\n",
        "      initial = Heuristic_Node(env, env.get_initial_state(), None, None, 0)\n",
        "      \n",
        "      open = heapdict.heapdict()\n",
        "      open[initial] = (initial.total_cost, initial.state) # add the start node to the priority queue with its g value\n",
        "      close = []; expanded = 0\n",
        "      while len(open) != 0:\n",
        "        n = open.popitem()[0] # pops node with lowest g value (from the priority queue)\n",
        "        close.append(n)\n",
        "      \n",
        "        # termination (valid solution)\n",
        "        if env.is_final_state(n.state):\n",
        "          return n.path(), n.total_cost, expanded\n",
        "\n",
        "        ex = n.expand()\n",
        "        expanded += 1\n",
        "        for son in ex:\n",
        "          if (not son.state in close) and (not son.state in open.keys()): # check if we've already visited the child node before\n",
        "            open[son] = (son.total_cost, son.state)\n",
        "          elif son.state in open.keys(): # if we've visited the child node before, check if it has a smaller g value now\n",
        "            # find the same node in the heapdict\n",
        "            prev = list(open.keys())[list(open.keys()).index(son.state)]\n",
        "            if son.total_cost < prev.total_cost:\n",
        "              del open[prev]\n",
        "              open[son] = (son.total_cost, son.state)\n",
        "      return None, None, None "
      ],
      "metadata": {
        "id": "r6GxboQbVq3Z"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UCS_agent = UCSAgent()\n",
        "actions, total_cost, expanded = UCS_agent.ucs_search(env)\n",
        "print(f\"Total_cost: {total_cost}\")\n",
        "print(f\"Expanded: {expanded}\")\n",
        "print(f\"Actions: {actions}\")"
      ],
      "metadata": {
        "id": "AV-S9bFMmDmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a83b232-d4bc-4020-f96a-b31cdd6c36bf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total_cost: 93.0\n",
            "Expanded: 56\n",
            "Actions: [1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_solution(actions, env)"
      ],
      "metadata": {
        "id": "jIxWnmIAamYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a803ef20-d19a-401f-b930-5464dc47bbda"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Down)\n",
            "\u001b[43mS\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mA\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[45m\u001b[45mG\u001b[0m\u001b[0m\n",
            "\n",
            "Timestep: 15\n",
            "State: 63\n",
            "Action: 0\n",
            "Cost: 1.0\n",
            "Total cost: 93.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Greedy Best First Search\n",
        "TO DO: implement Greedy Best First Search like shown in class.\n",
        "\n",
        "Note: The heurisitcs needed to be implemented. Instructions in dry pdf.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "36V_9xlScMGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GreedyAgent:\n",
        "    def __init__(self):\n",
        "      self.env = None\n",
        "\n",
        "    def Greedy_Best_First_search(self, env: FrozenLakeEnv) -> Tuple[List[int], int ,int]:\n",
        "      self.env = env\n",
        "      self.env.reset()\n",
        "      initial = Heuristic_Node(env, env.get_initial_state(), None, None, 0)\n",
        "      \n",
        "      open = heapdict.heapdict()\n",
        "      open[initial] = (initial.h, initial.state) # add the start node to the priority queue with its h value\n",
        "      close = []; expanded = 0\n",
        "      while len(open) != 0:\n",
        "        n = open.popitem()[0] # pops node with lowest h value (from the priority queue)\n",
        "        close.append(n)\n",
        "\n",
        "        # termination (valid solution)\n",
        "        if env.is_final_state(n.state):\n",
        "          return n.path(), n.total_cost, expanded\n",
        "\n",
        "        ex = n.expand()\n",
        "        expanded += 1\n",
        "        for son in ex:\n",
        "          if (not son.state in close) and (not son.state in open.keys()): # check if we've already visited the child node before\n",
        "            open[son] = (son.h, son.state)\n",
        "          # Greedy doesn't update values, so if a child is in closed we will never return it to open\n",
        "  \n",
        "      return None, None, None "
      ],
      "metadata": {
        "id": "12oCdLcScqSZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Greedy_agent = GreedyAgent()\n",
        "actions, total_cost, expanded = Greedy_agent.Greedy_Best_First_search(env)\n",
        "print(f\"Total_cost: {total_cost}\")\n",
        "print(f\"Expanded: {expanded}\")\n",
        "print(f\"Actions: {actions}\")"
      ],
      "metadata": {
        "id": "YZZmziDXp5Bo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3a9369-a5ea-4e7b-cf3a-0e2c2c856634"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total_cost: 113.0\n",
            "Expanded: 14\n",
            "Actions: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_solution(actions, env)"
      ],
      "metadata": {
        "id": "ynUOuI6UqKiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef489b7-0386-4295-98a5-190f798b5b75"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Down)\n",
            "\u001b[43mS\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mA\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[45m\u001b[45mG\u001b[0m\u001b[0m\n",
            "\n",
            "Timestep: 15\n",
            "State: 63\n",
            "Action: 0\n",
            "Cost: 1.0\n",
            "Total cost: 113.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Weighted A*\n",
        "TO DO: Implement Weighted A* like shown in class.\n",
        "\n",
        "Note:\n",
        "*   A parameter called `h_weight` is passed to `Greedy_Best_First_search()`, which indicates how much weight is given to the heuristics (ranging from 0 to 1).\n",
        "*   The heuristics needed to be implemented. Instructions in dry pdf.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sUnh0cwqrzfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightedAStarAgent:\n",
        "    def __init__(self):\n",
        "      self.env = None\n",
        "    \n",
        "    def weighted_A_star_search(self, env: FrozenLakeEnv, h_weight: float) -> Tuple[List[int], int ,int]:\n",
        "      self.env = env\n",
        "      self.env.reset()\n",
        "      \n",
        "      initial = Heuristic_Node(env, env.get_initial_state(), None, None, 0)\n",
        "      close = []\n",
        "      open = heapdict.heapdict()\n",
        "      open[initial] = (initial.h*h_weight + (1-h_weight)*initial.total_cost, initial.state)\n",
        "      expanded = 0\n",
        "\n",
        "      while len(open) != 0:\n",
        "        n = open.popitem()[0]\n",
        "        close.append(n)\n",
        "        if env.is_final_state(n.state):\n",
        "          return n.path(), n.total_cost, expanded\n",
        "        \n",
        "        ex = n.expand()\n",
        "        expanded += 1\n",
        "        for son in ex:\n",
        "          if (not son.state in close) and (not son.state in open.keys()):\n",
        "            open[son] = (son.h*h_weight + (1-h_weight)*son.total_cost, son.state)\n",
        "          elif son.state in open.keys():\n",
        "            prev = list(open.keys())[list(open.keys()).index(son.state)]\n",
        "            if son.total_cost < prev.total_cost:\n",
        "              del open[prev]\n",
        "              open[son] = (son.h*h_weight + (1-h_weight)*son.total_cost, son.state)\n",
        "          else: # nodes in closed can be returned to open (costs can be updated)\n",
        "            prev = close[close.index(son.state)]\n",
        "            if son.total_cost < prev.total_cost:\n",
        "              open[son] = (son.h*h_weight + (1-h_weight)*son.total_cost, son.state)\n",
        "              close.pop(close.index(son.state))\n",
        "              \n",
        "      return None, None, None     "
      ],
      "metadata": {
        "id": "slFZaOy9swBm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WA_agent = WeightedAStarAgent()\n",
        "actions, total_cost, expanded = WA_agent.weighted_A_star_search(env,h_weight=1)\n",
        "print(f\"Total_cost: {total_cost}\")\n",
        "print(f\"Expanded: {expanded}\")\n",
        "print(f\"Actions: {actions}\")"
      ],
      "metadata": {
        "id": "8xKSoHrMvJTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "298a5015-c2b6-4853-b8b6-9167aca8f820"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total_cost: 113.0\n",
            "Expanded: 14\n",
            "Actions: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_solution(actions, env)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcM0_32Netwc",
        "outputId": "35920343-9d1b-4f88-f8c9-48fe36bd7a98"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Down)\n",
            "\u001b[43mS\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mA\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[45m\u001b[45mG\u001b[0m\u001b[0m\n",
            "\n",
            "Timestep: 15\n",
            "State: 63\n",
            "Action: 0\n",
            "Cost: 1.0\n",
            "Total cost: 113.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. A*-epsilon:\n",
        "TO DO: implement A*-epsilon like shown in class.\n",
        "\n",
        "Note :\n",
        "*   A parameter called `epsilon` is passed to `A_star_epsilon_search()`.\n",
        "*   More Instructions in dry pdf.\n"
      ],
      "metadata": {
        "id": "K_nZTXgJxano"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AStarEpsilonAgent:\n",
        "    def __init__(self):\n",
        "      self.env = None\n",
        "\n",
        "    def build_focal(self, open, epsilon):\n",
        "      min_val = open.peekitem()[0].f\n",
        "      focal = heapdict.heapdict()\n",
        "      for node in open.keys():\n",
        "        if node.f <= (1+epsilon)*min_val:\n",
        "          focal[node] = (node.total_cost, node.state)\n",
        "          #focal[node] = (2*node.total_cost+node.h, node.state); for the dry question\n",
        "      return focal\n",
        " \n",
        "    def A_star_epsilon_search(self, env: FrozenLakeEnv, epsilon: int) -> Tuple[List[int], int ,int]:\n",
        "      self.env = env\n",
        "      self.env.reset()\n",
        "      initial = Heuristic_Node(env, env.get_initial_state(), None, None, 0)\n",
        "\n",
        "      open = heapdict.heapdict()\n",
        "      open[initial] = (initial.f, initial.state) # add the start node to the priority queue with its f value\n",
        "      close = []; expanded = 0\n",
        "      while len(open) != 0:\n",
        "        focal = self.build_focal(open,epsilon) # rebuild FOCAL each iteration\n",
        "        n = focal.peekitem()[0]  # most promising node from FOCAL\n",
        "        open.pop(n)\n",
        "        close.append(n)\n",
        "\n",
        "        # termination (valid solution)\n",
        "        if env.is_final_state(n.state):\n",
        "          return n.path(), n.total_cost, expanded\n",
        "\n",
        "        ex = n.expand()\n",
        "        expanded += 1\n",
        "        for son in ex:\n",
        "          if (not son.state in close) and (not son.state in open.keys()): # check if we've already visited the child node before\n",
        "            open[son] = (son.f, son.state)\n",
        "          elif son.state in open.keys():\n",
        "            prev = list(open.keys())[list(open.keys()).index(son.state)]\n",
        "            if son.total_cost < prev.total_cost:\n",
        "              del open[prev]\n",
        "              open[son] = (son.f, son.state)\n",
        "          else: # nodes in closed can be returned to open (costs can be updated)\n",
        "            prev = close[close.index(son.state)]\n",
        "            if son.total_cost < prev.total_cost:\n",
        "              open[son] = (son.f, son.state)\n",
        "              close.pop(close.index(son.state))\n",
        "      \n",
        "      return None, None, None "
      ],
      "metadata": {
        "id": "oaE7MW96xkHH"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A_star_epsilon_agent = AStarEpsilonAgent()\n",
        "actions, total_cost, expanded = A_star_epsilon_agent.A_star_epsilon_search(env,epsilon=0.5)\n",
        "print(f\"Total_cost: {total_cost}\")\n",
        "print(f\"Expanded: {expanded}\")\n",
        "print(f\"Actions: {actions}\")"
      ],
      "metadata": {
        "id": "Z27oUmACSXNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5298e831-bc9b-4044-f8a1-805d694898d7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total_cost: 93.0\n",
            "Expanded: 56\n",
            "Actions: [1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_solution(actions, env)"
      ],
      "metadata": {
        "id": "yBhTLtWP031Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96f732c-7a27-4d86-80fd-ab3b4d881532"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Down)\n",
            "\u001b[43mS\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mA\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[45m\u001b[45mG\u001b[0m\u001b[0m\n",
            "\n",
            "Timestep: 15\n",
            "State: 63\n",
            "Action: 0\n",
            "Cost: 1.0\n",
            "Total cost: 93.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission:\n",
        "Your agents will be tested at the end of the notebook. \n",
        "\n",
        "In the cell below, you will be able to verify whether your agents can be called properly after running the entire notebook.\n"
      ],
      "metadata": {
        "id": "MXDyMKvt81d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env2 = FrozenLakeEnv(MAPS[\"4x4\"])\n",
        "BFS_agent = BFSAgent() # GOOD TO GO\n",
        "actions, total_cost, expanded = BFS_agent.bfs_search(env)\n",
        "actions2, total_cost2, expanded2 = BFS_agent.bfs_search(env2)\n",
        "print(\"***BFS Agent***\")\n",
        "print(f\"env 8x8 : actions {actions}, Total_cost {total_cost}, Expanded {expanded}\")\n",
        "print(f\"env 4x4 : actions {actions2}, Total_cost {total_cost2}, Expanded {expanded2}\")\n",
        "###\n",
        "DFS_agent = DFSAgent() # GOOD TO GO\n",
        "actions, total_cost, expanded = DFS_agent.dfs_search(env)\n",
        "actions2, total_cost2, expanded2 = DFS_agent.dfs_search(env2)\n",
        "print(\"***DFS Agent***\")\n",
        "print(f\"env 8x8 : actions {actions}, Total_cost {total_cost}, Expanded {expanded}\")\n",
        "print(f\"env 4x4 : actions {actions2}, Total_cost {total_cost2}, Expanded {expanded2}\")\n",
        "###\n",
        "ID_DFS_agent = IDDFSAgent() # GOOD TO GO\n",
        "actions, total_cost, expanded = ID_DFS_agent.id_dfs_search(env)\n",
        "actions2, total_cost2, expanded2 = ID_DFS_agent.id_dfs_search(env2)\n",
        "print(\"***ID-DFS Agent***\")\n",
        "print(f\"env 8x8 : actions {actions}, Total_cost {total_cost}, Expanded {expanded}\")\n",
        "print(f\"env 4x4 : actions {actions2}, Total_cost {total_cost2}, Expanded {expanded2}\")\n",
        "###\n",
        "UCS_agent = UCSAgent() # GOOD TO GO\n",
        "actions, total_cost, expanded = UCS_agent.ucs_search(env)\n",
        "actions2, total_cost2, expanded2 = UCS_agent.ucs_search(env2)\n",
        "print(\"***UCS Agent***\")\n",
        "print(f\"env 8x8 : actions {actions}, Total_cost {total_cost}, Expanded {expanded}\")\n",
        "print(f\"env 4x4 : actions {actions2}, Total_cost {total_cost2}, Expanded {expanded2}\")\n",
        "###\n",
        "Greedy_agent = GreedyAgent() # GOOD TO GO\n",
        "actions, total_cost, expanded = Greedy_agent.Greedy_Best_First_search(env)\n",
        "actions2, total_cost2, expanded2 = Greedy_agent.Greedy_Best_First_search(env2)\n",
        "print(\"***Greedy Agent***\")\n",
        "print(f\"env 8x8 : actions {actions}, Total_cost {total_cost}, Expanded {expanded}\")\n",
        "print(f\"env 4x4 : actions {actions2}, Total_cost {total_cost2}, Expanded {expanded2}\")\n",
        "###\n",
        "WA_agent = WeightedAStarAgent() # GOOD TO GO\n",
        "actions, total_cost, expanded = WA_agent.weighted_A_star_search(env,h_weight=1)\n",
        "actions2, total_cost2, expanded2 = WA_agent.weighted_A_star_search(env2,h_weight=0.5)\n",
        "print(\"***Weighted A* Agent***\")\n",
        "print(f\"env 8x8 : actions {actions}, Total_cost {total_cost}, Expanded {expanded}\")\n",
        "print(f\"env 4x4 : actions {actions2}, Total_cost {total_cost2}, Expanded {expanded2}\")\n",
        "###\n",
        "A_star_epsilon_agent = AStarEpsilonAgent() # GOOD TO GO\n",
        "actions, total_cost, expanded = A_star_epsilon_agent.A_star_epsilon_search(env,epsilon=0.5)\n",
        "actions2, total_cost2, expanded2 = A_star_epsilon_agent.A_star_epsilon_search(env2,epsilon=100)\n",
        "print(\"***Epsilon A* Agent***\")\n",
        "print(f\"env 8x8 : actions {actions}, Total_cost {total_cost}, Expanded {expanded}\")\n",
        "print(f\"env 4x4 : actions {actions2}, Total_cost {total_cost2}, Expanded {expanded2}\")"
      ],
      "metadata": {
        "id": "-yujJqR89oNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b49983-f245-45d8-dfa4-ce6ebad421ce"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***BFS Agent***\n",
            "env 8x8 : actions [0, 0, 0, 1, 0, 0, 0, 1, 1], Total_cost 164.0, Expanded 55\n",
            "env 4x4 : actions [0, 0, 1, 0, 1, 1], Total_cost 51.0, Expanded 14\n",
            "***DFS Agent***\n",
            "env 8x8 : actions [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0, 1, 1], Total_cost 148.0, Expanded 20\n",
            "env 4x4 : actions [0, 0, 1, 0, 1, 1], Total_cost 51.0, Expanded 7\n",
            "***ID-DFS Agent***\n",
            "env 8x8 : actions [0, 0, 0, 1, 1, 1, 0, 0, 0], Total_cost 155.0, Expanded 360\n",
            "env 4x4 : actions [0, 0, 1, 0, 1, 1], Total_cost 51.0, Expanded 38\n",
            "***UCS Agent***\n",
            "env 8x8 : actions [1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0], Total_cost 93.0, Expanded 56\n",
            "env 4x4 : actions [1, 1, 0, 0, 0, 1], Total_cost 51.0, Expanded 15\n",
            "***Greedy Agent***\n",
            "env 8x8 : actions [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], Total_cost 113.0, Expanded 14\n",
            "env 4x4 : actions [1, 1, 0, 0, 0, 1], Total_cost 51.0, Expanded 9\n",
            "***Weighted A* Agent***\n",
            "env 8x8 : actions [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], Total_cost 113.0, Expanded 14\n",
            "env 4x4 : actions [1, 1, 0, 0, 0, 1], Total_cost 51.0, Expanded 15\n",
            "***Epsilon A* Agent***\n",
            "env 8x8 : actions [1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0], Total_cost 93.0, Expanded 56\n",
            "env 4x4 : actions [1, 1, 0, 0, 0, 1], Total_cost 51.0, Expanded 15\n"
          ]
        }
      ]
    }
  ]
}